#!/usr/bin/env python3
"""
ğŸ” Agent 1: Trend Researcher
ChuyÃªn gia phÃ¢n tÃ­ch xu hÆ°á»›ng YouTube Kids (2-8 tuá»•i).

TÃ¬m kiáº¿m vÃ  phÃ¢n tÃ­ch:
- Xu hÆ°á»›ng Ã¢m nháº¡c/vÅ© Ä‘iá»‡u Ä‘ang viral
- Chá»§ Ä‘á» giÃ¡o dá»¥c thá»‹nh hÃ nh
- Tá»« khÃ³a cÃ³ lÆ°á»£t tÃ¬m kiáº¿m cao

Usage:
    python3 trend_researcher.py                          # TÃ¬m máº·c Ä‘á»‹nh 10 xu hÆ°á»›ng
    python3 trend_researcher.py --max 5 --age-range 2-5  # Lá»c theo Ä‘á»™ tuá»•i
    python3 trend_researcher.py --category music         # Lá»c theo loáº¡i
    python3 trend_researcher.py --dry-run                # Test khÃ´ng lÆ°u file
"""

import argparse
import json
import os
import subprocess
import sys
from datetime import datetime
from pathlib import Path

# Add shared/ dir to path (myshort/shared/)
MYSHORT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(MYSHORT_ROOT / "shared"))
from utils import (
    setup_logging, get_config, ensure_output_dirs, save_json,
    load_safety_keywords, print_header, print_step, print_success,
    print_warning, print_error, safe_filename, get_output_dir,
    send_telegram
)

logger = setup_logging("TrendResearcher")

# â”€â”€ Search Queries â”€â”€
TREND_QUERIES = {
    "music_dance": [
        "YouTube Kids trending songs {year}",
        "viral nursery rhymes kids {year}",
        "children dance songs popular {year}",
        "cocomelon style songs trending",
        "baby shark style viral kids songs",
        "kids pop music dance videos trending",
    ],
    "education": [
        "learning videos for toddlers trending {year}",
        "educational kids YouTube viral {year}",
        "counting colors shapes kids popular videos",
        "alphabet songs trending kids {year}",
        "STEM kids videos popular {year}",
    ],
    "characters": [
        "popular kids cartoon characters {year}",
        "animated kids shows trending YouTube",
        "cute animal characters kids videos viral",
    ],
    "general": [
        "YouTube Kids most viewed this week",
        "kids content trends {year} analysis",
        "children video viral formula {year}",
    ]
}

def run_search(query, max_results=5, search_type="text"):
    """TÃ¬m kiáº¿m trá»±c tiáº¿p qua Tavily API (self-contained, khÃ´ng phá»¥ thuá»™c search.py)."""
    config = get_config()
    api_key = config.get("tavily_api_key", "")

    if not api_key:
        logger.warning("TAVILY_API_KEY chÆ°a set â€” bá» qua query: " + query)
        return []

    url = "https://api.tavily.com/search"
    payload = {
        "api_key": api_key,
        "query": query,
        "max_results": max_results,
        "search_depth": "basic",
        "include_answer": False,
    }

    if search_type == "news":
        payload["topic"] = "news"

    try:
        import requests
        response = requests.post(url, json=payload, timeout=15)
        response.raise_for_status()
        data = response.json()

        results = []
        for item in data.get("results", []):
            results.append({
                "title": item.get("title", ""),
                "url": item.get("url", ""),
                "snippet": item.get("content", ""),
            })
        return results

    except Exception as e:
        logger.warning(f"Tavily search failed for '{query[:40]}': {e}")
        return []

def analyze_trends(search_results, category, age_range):
    """PhÃ¢n tÃ­ch káº¿t quáº£ tÃ¬m kiáº¿m thÃ nh xu hÆ°á»›ng cáº¥u trÃºc."""
    trends = []
    safety = load_safety_keywords()
    blocked = [kw.lower() for kw in safety.get("blocked_keywords", [])]
    
    for result in search_results:
        if isinstance(result, dict):
            title = result.get("title", result.get("raw", ""))
            url = result.get("url", result.get("href", ""))
            snippet = result.get("snippet", result.get("body", ""))
        else:
            title = str(result)
            url = ""
            snippet = ""
        
        # Safety check
        content_lower = f"{title} {snippet}".lower()
        if any(kw in content_lower for kw in blocked):
            logger.debug(f"Blocked unsafe content: {title[:50]}")
            continue
        
        trend = {
            "name": title[:100] if title else "Unknown Trend",
            "category": category,
            "target_age": age_range,
            "url": url,
            "snippet": snippet[:200] if snippet else "",
            "keywords": extract_keywords(title, snippet),
            "relevance": calculate_relevance(title, snippet, category),
        }
        trends.append(trend)
    
    # Sort by relevance
    trends.sort(key=lambda t: t["relevance"], reverse=True)
    return trends

def extract_keywords(title, snippet):
    """TrÃ­ch xuáº¥t tá»« khÃ³a chÃ­nh tá»« title vÃ  snippet."""
    import re
    text = f"{title} {snippet}".lower()
    # Tá»« khÃ³a phá»• biáº¿n trong lÄ©nh vá»±c kids content
    kids_keywords = [
        "nursery rhyme", "kids song", "children", "toddler", "baby",
        "dance", "sing", "learn", "count", "color", "shape", "alphabet",
        "cartoon", "animation", "cocomelon", "pinkfong", "baby shark",
        "educational", "fun", "play", "game", "story", "fairy tale",
        "animal", "dinosaur", "vehicle", "truck", "train",
        "rainbow", "music", "lullaby", "bedtime"
    ]
    
    found = [kw for kw in kids_keywords if kw in text]
    return found[:5]  # Top 5 keywords

def calculate_relevance(title, snippet, category):
    """TÃ­nh Ä‘iá»ƒm relevance (0-100) dá»±a trÃªn ná»™i dung."""
    score = 50  # Base score
    text = f"{title} {snippet}".lower()
    
    # Boost for viral indicators
    viral_words = ["viral", "trending", "popular", "million views", "top", "best", "hit"]
    for word in viral_words:
        if word in text:
            score += 10
    
    # Boost for kids-specific content
    kids_words = ["kids", "children", "toddler", "baby", "nursery", "learn"]
    for word in kids_words:
        if word in text:
            score += 5
    
    # Boost for category match
    if category.replace("_", " ") in text:
        score += 10
    
    return min(score, 100)

def research_trends(categories=None, max_per_category=5, age_range="2-8", dry_run=False):
    """Quy trÃ¬nh chÃ­nh: nghiÃªn cá»©u xu hÆ°á»›ng."""
    year = datetime.now().year
    
    if categories is None:
        categories = list(TREND_QUERIES.keys())
    
    all_trends = []
    total_queries = sum(len(TREND_QUERIES.get(cat, [])) for cat in categories)
    query_count = 0
    
    print_header("Agent 1: Trend Researcher", "ğŸ”")
    print(f"  ğŸ“… NgÃ y: {datetime.now().strftime('%Y-%m-%d')}")
    print(f"  ğŸ‘¶ Äá»™ tuá»•i: {age_range}")
    print(f"  ğŸ“‚ Categories: {', '.join(categories)}")
    print(f"  ğŸ” Tá»•ng queries: {total_queries}\n")
    
    for category in categories:
        queries = TREND_QUERIES.get(category, [])
        print(f"\n  ğŸ“ Category: {category}")
        
        category_trends = []
        for query_template in queries:
            query = query_template.format(year=year)
            query_count += 1
            print_step(query_count, total_queries, f"Searching: {query[:60]}...")
            
            if dry_run:
                # Fake results for dry-run
                category_trends.append({
                    "name": f"[DRY-RUN] Sample trend for: {query[:40]}",
                    "category": category,
                    "target_age": age_range,
                    "url": "https://example.com",
                    "snippet": "This is a dry-run sample result",
                    "keywords": ["sample", "dry-run"],
                    "relevance": 70,
                })
                continue
            
            results = run_search(query, max_results=max_per_category)
            trends = analyze_trends(results, category, age_range)
            category_trends.extend(trends)
        
        # Deduplicate and take top N
        seen = set()
        unique = []
        for t in category_trends:
            key = t["name"][:50].lower()
            if key not in seen:
                seen.add(key)
                unique.append(t)
        
        all_trends.extend(unique[:max_per_category])
        print_success(f"  TÃ¬m Ä‘Æ°á»£c {len(unique)} xu hÆ°á»›ng trong {category}")
    
    # Pick recommended topic
    recommended = None
    if all_trends:
        all_trends.sort(key=lambda t: t["relevance"], reverse=True)
        recommended = all_trends[0]
    
    return {
        "date": datetime.now().strftime("%Y-%m-%d"),
        "age_range": age_range,
        "categories": categories,
        "total_trends": len(all_trends),
        "trends": all_trends,
        "recommended_topic": recommended,
    }

def main():
    parser = argparse.ArgumentParser(
        description="ğŸ” Agent 1: Trend Researcher â€” TÃ¬m xu hÆ°á»›ng YouTube Kids"
    )
    parser.add_argument("--max", type=int, default=5,
                       help="Sá»‘ xu hÆ°á»›ng tá»‘i Ä‘a má»—i category (máº·c Ä‘á»‹nh: 5)")
    parser.add_argument("--age-range", default="2-8",
                       help="Äá»™ tuá»•i má»¥c tiÃªu (máº·c Ä‘á»‹nh: 2-8)")
    parser.add_argument("--category", choices=["music_dance", "education", "characters", "general"],
                       help="Lá»c 1 category cá»¥ thá»ƒ")
    parser.add_argument("--dry-run", action="store_true",
                       help="Test workflow khÃ´ng gá»i search tháº­t")
    parser.add_argument("--output", help="ÄÆ°á»ng dáº«n file output (máº·c Ä‘á»‹nh: auto)")
    parser.add_argument("--json", action="store_true",
                       help="In káº¿t quáº£ ra stdout dáº¡ng JSON")
    args = parser.parse_args()
    
    categories = [args.category] if args.category else None
    
    # Run research
    result = research_trends(
        categories=categories,
        max_per_category=args.max,
        age_range=args.age_range,
        dry_run=args.dry_run,
    )
    
    # Output
    if args.json:
        print(json.dumps(result, ensure_ascii=False, indent=2))
        return
    
    # Save to file
    output_dir = ensure_output_dirs()
    output_path = args.output or str(
        output_dir / "trends" / f"trend-{datetime.now().strftime('%Y%m%d')}.json"
    )
    save_json(result, output_path)
    
    # Summary
    print(f"\n{'â”' * 50}")
    print(f"ğŸ“Š Káº¾T QUáº¢: {result['total_trends']} xu hÆ°á»›ng tÃ¬m Ä‘Æ°á»£c")
    print(f"ğŸ“ File: {output_path}")
    
    if result["recommended_topic"]:
        rec = result["recommended_topic"]
        print(f"\nğŸ† TOP RECOMMENDATION:")
        print(f"   TÃªn: {rec['name'][:80]}")
        print(f"   Category: {rec['category']}")
        print(f"   Keywords: {', '.join(rec.get('keywords', []))}")
        print(f"   Relevance: {rec['relevance']}/100")
    
    print(f"{'â”' * 50}\n")
    
    # â”€â”€ Telegram Notification â”€â”€
    msg_lines = ["ğŸ” *Agent 1: Trend Researcher*", ""]
    msg_lines.append(f"ğŸ“… NgÃ y: {result.get('date', 'N/A')}")
    msg_lines.append(f"ğŸ“Š TÃ¬m Ä‘Æ°á»£c: {result['total_trends']} xu hÆ°á»›ng\n")
    
    for i, t in enumerate(result.get('trends', [])[:8]):
        name = t.get('name', '?')[:60]
        cat = t.get('category', '?')
        score = t.get('relevance', 0)
        kwords = ', '.join(t.get('keywords', [])[:5])
        msg_lines.append(f"{i+1}. [{cat}] *{name}*")
        msg_lines.append(f"   Score: {score} | {kwords}")
    
    if result.get('recommended_topic'):
        rec = result['recommended_topic']
        msg_lines.append(f"\nğŸ† *Gá»¢I Ã:* {rec.get('name', '?')[:80]}")
        msg_lines.append(f"Keywords: {', '.join(rec.get('keywords', []))}")
    
    if not result.get('trends'):
        msg_lines.append("âš ï¸ KhÃ´ng tÃ¬m Ä‘Æ°á»£c xu hÆ°á»›ng nÃ o.")
    
    send_telegram("\n".join(msg_lines))
    print_success("ÄÃ£ gá»­i káº¿t quáº£ qua Telegram")

if __name__ == "__main__":
    main()
